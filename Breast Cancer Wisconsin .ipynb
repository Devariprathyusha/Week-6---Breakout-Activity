{
  "metadata": {
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": "import pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\nfrom sklearn.decomposition import PCA\n\n# Load dataset\nfile_path = 'data (2).csv'\ndata = pd.read_csv(file_path)\n\n# Drop unnecessary columns\ndata = data.drop(columns=['id', 'Unnamed: 32'])\n\n# Map target values to binary (M = 1, B = 0)\ndata['diagnosis'] = data['diagnosis'].map({'M': 1, 'B': 0})\n\n# Split dataset into features and target\nX = data.drop(columns=['diagnosis'])\ny = data['diagnosis']\n\n# Split into train and test sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n\n# Models to evaluate\nmodels = {\n    'Decision Tree': DecisionTreeClassifier(),\n    'KNN': KNeighborsClassifier(),\n    'Random Forest': RandomForestClassifier(),\n    'Naive Bayes': GaussianNB()\n}\n\n# Dictionary to store the results\nresults = {}\n\n# Train, predict and evaluate each model\nfor name, model in models.items():\n    model.fit(X_train, y_train)  # Train the model\n    y_pred = model.predict(X_test)  # Predict on the test set\n\n    # Calculate evaluation metrics\n    accuracy = accuracy_score(y_test, y_pred)\n    precision = precision_score(y_test, y_pred)\n    recall = recall_score(y_test, y_pred)\n    f1 = f1_score(y_test, y_pred)\n\n    # Store the results\n    results[name] = {\n        'Accuracy': accuracy,\n        'Precision': precision,\n        'Recall': recall,\n        'F1-Score': f1\n    }\n\n# Print the results\nfor model, metrics in results.items():\n    print(f\"Results for {model}:\")\n    for metric, value in metrics.items():\n        print(f\"  {metric}: {value:.4f}\")\n\n# Apply PCA for dimensionality reduction\npca = PCA(n_components=2)\nX_train_pca = pca.fit_transform(X_train)\nX_test_pca = pca.transform(X_test)\n\n# Re-train models with PCA-applied data\nprint(\"\\nResults after PCA:\")\nfor name, model in models.items():\n    model.fit(X_train_pca, y_train)\n    y_pred_pca = model.predict(X_test_pca)\n\n    # Calculate evaluation metrics\n    accuracy = accuracy_score(y_test, y_pred_pca)\n    precision = precision_score(y_test, y_pred_pca)\n    recall = recall_score(y_test, y_pred_pca)\n    f1 = f1_score(y_test, y_pred_pca)\n\n    # Print the results after PCA\n    print(f\"\\nResults for {name} after PCA:\")\n    print(f\"  Accuracy: {accuracy:.4f}\")\n    print(f\"  Precision: {precision:.4f}\")\n    print(f\"  Recall: {recall:.4f}\")\n    print(f\"  F1-Score: {f1:.4f}\")\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stderr",
          "text": "<ipython-input-1-b0ea7d16d198>:1: DeprecationWarning: \nPyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\nbut was not found to be installed on your system.\nIf this would cause problems for you,\nplease provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n        \n  import pandas as pd\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Results for Decision Tree:\n  Accuracy: 0.9240\n  Precision: 0.8788\n  Recall: 0.9206\n  F1-Score: 0.8992\nResults for KNN:\n  Accuracy: 0.9591\n  Precision: 0.9828\n  Recall: 0.9048\n  F1-Score: 0.9421\nResults for Random Forest:\n  Accuracy: 0.9708\n  Precision: 0.9833\n  Recall: 0.9365\n  F1-Score: 0.9593\nResults for Naive Bayes:\n  Accuracy: 0.9415\n  Precision: 0.9344\n  Recall: 0.9048\n  F1-Score: 0.9194\n\nResults after PCA:\n\nResults for Decision Tree after PCA:\n  Accuracy: 0.9240\n  Precision: 0.8676\n  Recall: 0.9365\n  F1-Score: 0.9008\n\nResults for KNN after PCA:\n  Accuracy: 0.9591\n  Precision: 0.9516\n  Recall: 0.9365\n  F1-Score: 0.9440\n\nResults for Random Forest after PCA:\n  Accuracy: 0.9532\n  Precision: 0.9365\n  Recall: 0.9365\n  F1-Score: 0.9365\n\nResults for Naive Bayes after PCA:\n  Accuracy: 0.9181\n  Precision: 1.0000\n  Recall: 0.7778\n  F1-Score: 0.8750\n",
          "output_type": "stream"
        }
      ],
      "execution_count": 1
    },
    {
      "cell_type": "code",
      "source": "",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}